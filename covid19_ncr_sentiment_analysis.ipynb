{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:41:50.598331Z",
     "start_time": "2021-01-18T14:41:14.126560Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.words('english')\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:42:14.578723Z",
     "start_time": "2021-01-18T14:42:13.218695Z"
    }
   },
   "outputs": [],
   "source": [
    "#!dir ..\\..\\1. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:43:29.249501Z",
     "start_time": "2021-01-18T14:43:29.244515Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_tweets = pd.read_csv(r\"../../1. Datasets/NLP Datasets/2. Labelled Tweets/ncr.csv\")\n",
    "df_tweets = pd.read_csv(\"ncr.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:47:40.860660Z",
     "start_time": "2021-01-18T14:47:40.850687Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text, tagalog_letters):\n",
    "    ''' Pre process and convert texts to a list of words \n",
    "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
    "    text = tagalog_letters(text)\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"http\\S.*$\",\" \", text) # removing twitter urls\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \"\", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "        \n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "        \n",
    "    text = [word for word in text.split(' ') if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:47:46.493406Z",
     "start_time": "2021-01-18T14:47:46.211162Z"
    }
   },
   "outputs": [],
   "source": [
    "df_tweets.tweets = df_tweets.tweets.apply(lambda x: text_to_word_list(x, unidecode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      mayor jerry trenas representing iloilo city go...\n",
       "1      online muna tayo mga kap para sa bayan sa mga ...\n",
       "2      best feeling 8 hours shift covid unit removing...\n",
       "3      dont forget covid 19 safety protocols us still...\n",
       "4      taena nitong covid parang produkto daming vari...\n",
       "                             ...                        \n",
       "177    nakaka sad doctors nurses died frontliners cov...\n",
       "178    dati everyday kung mag update ang doh covid re...\n",
       "179    78 efficacy 100 prevention severe cases covid ...\n",
       "180     kitsunemaisonn chefadobo hahahahaahaa love ko...\n",
       "181    eto kabado na naman kami sa office 3 na pala c...\n",
       "Name: tweets, Length: 182, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Usually splitting is done before vectorization (i.e. the vectorizer shouldn't be fitted with the test set of tweets). However, since we have a small dataset, it is more likely for words in test set to not be available in the train set (which will cause inaccuracies in the model). So in this case, let's just vectorize the full dataset before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:49:13.629390Z",
     "start_time": "2021-01-18T14:49:12.298642Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:50:59.484905Z",
     "start_time": "2021-01-18T14:50:59.468948Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(norm=None)\n",
    "tfidf.fit(df_tweets.tweets)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "X = pd.DataFrame(tfidf.transform(df_tweets.tweets).todense(), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:53:45.915412Z",
     "start_time": "2021-01-18T14:53:45.912420Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df_tweets.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:54:19.331779Z",
     "start_time": "2021-01-18T14:54:19.305849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (145, 1175)\n",
      "X_val shape:  (37, 1175)\n",
      "y_train shape:  (145,)\n",
      "y_val shape:  (37,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "# X_train_text = X_train['tweets']\n",
    "# X_val_text = X_val['tweets']\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_val shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:54:34.986268Z",
     "start_time": "2021-01-18T14:54:34.652923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "stratk_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:54:38.641243Z",
     "start_time": "2021-01-18T14:54:38.253975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53333333 0.6        0.6        0.53333333 0.4        0.57142857\n",
      " 0.42857143 0.35714286 0.42857143 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "kfold_score = cross_val_score(clf, X_train, y_train, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(kfold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T14:54:45.580750Z",
     "start_time": "2021-01-18T14:54:45.575763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.52"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kfold logistic regression score\n",
    "round(np.mean(kfold_score)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grids = {'learning_rate': [.2, 0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [3, 4, 6, 10, 14],\n",
    "              'min_samples_leaf': [2, 3, 4],\n",
    "              'max_features': [.5,.3, .2] \n",
    "}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T15:17:29.385385Z",
     "start_time": "2021-01-18T15:17:29.321544Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import pandas as pd\n",
    "import pylab as plot\n",
    "import lmfit as lf\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from pandas import Series\n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR, SVC, LinearSVC, LinearSVR\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "\n",
    "import xgboost as XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "def classification(X, y, scaler=None):\n",
    "    kneighbors = range(1, 20)\n",
    "    smoothing = np.logspace(1, 15, num=10)\n",
    "    a = np.logspace(-5, 5, num=10)\n",
    "    gamma_list = np.logspace(-5, 5, num=10)\n",
    "    depth_settings = range(1, 15)\n",
    "    tolerance = np.logspace(-5, 5, num=10)\n",
    "    \n",
    "    knn_c = KNeighborsClassifier(n_jobs=-1)\n",
    "    log_res_l1 = LogisticRegression(penalty='l1', max_iter=1000,\n",
    "                             solver='liblinear', n_jobs=-1)\n",
    "    log_res_l2 = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "    lin_svc_l1 = LinearSVC(penalty='l1', dual=False, max_iter=10000)\n",
    "    lin_svc_l2 = LinearSVC(penalty='l2', max_iter=10000)\n",
    "    # cl7 = SVC(kernel='poly', degree=3)\n",
    "    nsvm_rbf = SVC(kernel='rbf')\n",
    "    d_tree = DecisionTreeClassifier(random_state=0, max_depth=depth_settings)\n",
    "    r_forest = RandomForestClassifier(max_depth=depth_settings, random_state=0)\n",
    "    xg_boost = XGBClassifier.XGBClassifier(random_state=0, max_depth=depth_settings, learning_rate=0.01)\n",
    "#     mult_nb = MultinomialNB(alpha=a)\n",
    "#     n_bayes = GaussianNB()\n",
    "    \n",
    "\n",
    "    est = [('KNN', knn_c, {'n_neighbors':kneighbors}),\n",
    "           ('Logistic Regression (L1)', log_res_l1, {'C':a}),\n",
    "           ('Logistic Regression (L2)', log_res_l2, {'C':a}),\n",
    "           ('Linear SVM (L1)', lin_svc_l1, {'C':a}),\n",
    "           ('Linear SVM (L2)', lin_svc_l2, {'C':a}),\n",
    "           ('NonLinear SVM (RBF)', nsvm_rbf, {'C':a, 'gamma':gamma_list}),\n",
    "           ('Decision Tree',d_tree,{'max_depth':depth_settings}),\n",
    "           ('Random Forest',r_forest,{'max_depth':depth_settings}),\n",
    "           ('XGBoost',xg_boost,{'max_depth':depth_settings})]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
    "    \n",
    "    if scaler == 'ss':\n",
    "        scale = StandardScaler()\n",
    "        X_train = scale.fit_transform(X = X_train)\n",
    "        X_val = scale.transform(X = X_val)\n",
    "    elif scaler == 'mm':\n",
    "        scale = MinMaxScaler()\n",
    "        X_train = scale.fit_transform(X_train)\n",
    "        X_val = scale.transform(X_val)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    models = {}\n",
    "    for e in est:\n",
    "        print(f'Training {e[0]}')\n",
    "        start_time = time.time()\n",
    "        gs_cv = GridSearchCV(e[1], param_grid=e[2], n_jobs=-1)\n",
    "        gs_cv.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        models[e[0]] = gs_cv, elapsed_time\n",
    "        print(f'Training {e[0]} complete in {elapsed_time} seconds \\n')\n",
    "    \n",
    "    accuracy_summary ={}\n",
    "    for m in models:\n",
    "        test_acc = models[m][0].best_estimator_.score(X_val, y_val)\n",
    "        train_acc = models[m][0].best_estimator_.score(X_train, y_train)\n",
    "        best_param = models[m][0].best_params_\n",
    "        accuracy_summary[m] = test_acc, train_acc, best_param, models[m][1]\n",
    "    \n",
    "    target_count = np.unique(y, return_counts=True)[1]\n",
    "    pcc = np.sum((target_count/target_count.sum())**2)\n",
    "        \n",
    "    results_summary = pd.DataFrame.from_dict(accuracy_summary, orient='index', columns=['Test Accuracy', 'Training Accuracy', 'Best Parameters', 'Run Time'])\n",
    "    results_summary['Test Accuracy / PCC'] = results_summary['Test Accuracy']/pcc\n",
    "    \n",
    "    #linear\n",
    "    summary={}\n",
    "    methods_l = ['Logistic Regression (L1)','Logistic Regression (L2)',\n",
    "              'Linear SVM (L1)','Linear SVM (L2)']\n",
    "\n",
    "    for m in methods_l:\n",
    "        pred = []\n",
    "        for i,j in list(zip(X.columns, (models[m][0].best_estimator_.coef_))):\n",
    "            pred.append([i,j[np.abs(j).argmax()]])\n",
    "            summary[m] = pred\n",
    "\n",
    "    #ensamble\n",
    "    methods_e = ['Decision Tree', 'Random Forest','XGBoost']\n",
    "    pred = []\n",
    "    for m in methods_e:\n",
    "        coefs = [(X.columns[(models[m][0].best_estimator_.feature_importances_).argsort()[-3:]\n",
    "                           ], models[m][0].best_estimator_.feature_importances_[\n",
    "            (models[m][0].best_estimator_.feature_importances_).argsort()[-3:]])]\n",
    "\n",
    "        coeff = list(zip(*coefs[0]))\n",
    "        pred.append(coeff)\n",
    "        summary[m] = pred[0]\n",
    "\n",
    "    #no coeff\n",
    "    methods_no = ['KNN','NonLinear SVM (RBF)']\n",
    "    for m in methods_no:\n",
    "        summary[m] = [[np.nan],[np.nan],[np.nan]]\n",
    "\n",
    "    df_summary_c1 = pd.DataFrame.from_dict(summary)\n",
    "        \n",
    "    return results_summary.join(df_summary_c1.T, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T15:18:52.979704Z",
     "start_time": "2021-01-18T15:17:30.027287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN\n",
      "Training KNN complete in 8.864726543426514 seconds \n",
      "\n",
      "Training Logistic Regression (L1)\n",
      "Training Logistic Regression (L1) complete in 1.1672613620758057 seconds \n",
      "\n",
      "Training Logistic Regression (L2)\n",
      "Training Logistic Regression (L2) complete in 2.368738889694214 seconds \n",
      "\n",
      "Training Linear SVM (L1)\n",
      "Training Linear SVM (L1) complete in 3.0266990661621094 seconds \n",
      "\n",
      "Training Linear SVM (L2)\n",
      "Training Linear SVM (L2) complete in 1.145054817199707 seconds \n",
      "\n",
      "Training NonLinear SVM (RBF)\n",
      "Training NonLinear SVM (RBF) complete in 14.524542331695557 seconds \n",
      "\n",
      "Training Decision Tree\n",
      "Training Decision Tree complete in 2.248163938522339 seconds \n",
      "\n",
      "Training Random Forest\n",
      "Training Random Forest complete in 7.9939186573028564 seconds \n",
      "\n",
      "Training XGBoost\n",
      "Training XGBoost complete in 72.68832874298096 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_performances = classification(X,y,scaler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Test Accuracy / PCC</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>8.864727</td>\n",
       "      <td>1.561884</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (L1)</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 3.593813663804626}</td>\n",
       "      <td>1.167261</td>\n",
       "      <td>1.703873</td>\n",
       "      <td>[000, 3.0968197254487153]</td>\n",
       "      <td>[10, -3.1131409340708296]</td>\n",
       "      <td>[100, 1.7870790377486958]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (L2)</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>{'C': 0.021544346900318846}</td>\n",
       "      <td>2.368739</td>\n",
       "      <td>1.632878</td>\n",
       "      <td>[000, 0.09030672183600422]</td>\n",
       "      <td>[10, 0.07339367682126371]</td>\n",
       "      <td>[100, 0.11077148985498345]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM (L1)</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 0.2782559402207126}</td>\n",
       "      <td>3.026699</td>\n",
       "      <td>1.632878</td>\n",
       "      <td>[000, 0.5895135640250133]</td>\n",
       "      <td>[10, -0.5892319061480008]</td>\n",
       "      <td>[100, 0.3768937967319165]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM (L2)</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>{'C': 0.0016681005372000592}</td>\n",
       "      <td>1.145055</td>\n",
       "      <td>1.703873</td>\n",
       "      <td>[000, -0.038204948000019924]</td>\n",
       "      <td>[10, -0.07851418749006081]</td>\n",
       "      <td>[100, -0.06121857876659567]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NonLinear SVM (RBF)</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>{'C': 599.4842503189421, 'gamma': 1e-05}</td>\n",
       "      <td>14.524542</td>\n",
       "      <td>1.703873</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2.248164</td>\n",
       "      <td>1.632878</td>\n",
       "      <td>(free, 0.127286770052531)</td>\n",
       "      <td>(aeuroesuposta, 0.13115910517599078)</td>\n",
       "      <td>(covid, 0.2550966572188687)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>7.993919</td>\n",
       "      <td>1.490889</td>\n",
       "      <td>(free, 0.127286770052531)</td>\n",
       "      <td>(aeuroesuposta, 0.13115910517599078)</td>\n",
       "      <td>(covid, 0.2550966572188687)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>72.688329</td>\n",
       "      <td>1.774868</td>\n",
       "      <td>(free, 0.127286770052531)</td>\n",
       "      <td>(aeuroesuposta, 0.13115910517599078)</td>\n",
       "      <td>(covid, 0.2550966572188687)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Test Accuracy  Training Accuracy  \\\n",
       "KNN                            0.594595           0.758621   \n",
       "Logistic Regression (L1)       0.648649           1.000000   \n",
       "Logistic Regression (L2)       0.621622           0.972414   \n",
       "Linear SVM (L1)                0.621622           1.000000   \n",
       "Linear SVM (L2)                0.648649           0.965517   \n",
       "NonLinear SVM (RBF)            0.648649           0.979310   \n",
       "Decision Tree                  0.621622           0.682759   \n",
       "Random Forest                  0.567568           0.696552   \n",
       "XGBoost                        0.675676           0.703448   \n",
       "\n",
       "                                                   Best Parameters   Run Time  \\\n",
       "KNN                                            {'n_neighbors': 11}   8.864727   \n",
       "Logistic Regression (L1)                  {'C': 3.593813663804626}   1.167261   \n",
       "Logistic Regression (L2)               {'C': 0.021544346900318846}   2.368739   \n",
       "Linear SVM (L1)                          {'C': 0.2782559402207126}   3.026699   \n",
       "Linear SVM (L2)                       {'C': 0.0016681005372000592}   1.145055   \n",
       "NonLinear SVM (RBF)       {'C': 599.4842503189421, 'gamma': 1e-05}  14.524542   \n",
       "Decision Tree                                     {'max_depth': 5}   2.248164   \n",
       "Random Forest                                    {'max_depth': 10}   7.993919   \n",
       "XGBoost                                           {'max_depth': 3}  72.688329   \n",
       "\n",
       "                          Test Accuracy / PCC                             0  \\\n",
       "KNN                                  1.561884                         [nan]   \n",
       "Logistic Regression (L1)             1.703873     [000, 3.0968197254487153]   \n",
       "Logistic Regression (L2)             1.632878    [000, 0.09030672183600422]   \n",
       "Linear SVM (L1)                      1.632878     [000, 0.5895135640250133]   \n",
       "Linear SVM (L2)                      1.703873  [000, -0.038204948000019924]   \n",
       "NonLinear SVM (RBF)                  1.703873                         [nan]   \n",
       "Decision Tree                        1.632878     (free, 0.127286770052531)   \n",
       "Random Forest                        1.490889     (free, 0.127286770052531)   \n",
       "XGBoost                              1.774868     (free, 0.127286770052531)   \n",
       "\n",
       "                                                             1  \\\n",
       "KNN                                                      [nan]   \n",
       "Logistic Regression (L1)             [10, -3.1131409340708296]   \n",
       "Logistic Regression (L2)             [10, 0.07339367682126371]   \n",
       "Linear SVM (L1)                      [10, -0.5892319061480008]   \n",
       "Linear SVM (L2)                     [10, -0.07851418749006081]   \n",
       "NonLinear SVM (RBF)                                      [nan]   \n",
       "Decision Tree             (aeuroesuposta, 0.13115910517599078)   \n",
       "Random Forest             (aeuroesuposta, 0.13115910517599078)   \n",
       "XGBoost                   (aeuroesuposta, 0.13115910517599078)   \n",
       "\n",
       "                                                    2  \n",
       "KNN                                             [nan]  \n",
       "Logistic Regression (L1)    [100, 1.7870790377486958]  \n",
       "Logistic Regression (L2)   [100, 0.11077148985498345]  \n",
       "Linear SVM (L1)             [100, 0.3768937967319165]  \n",
       "Linear SVM (L2)           [100, -0.06121857876659567]  \n",
       "NonLinear SVM (RBF)                             [nan]  \n",
       "Decision Tree             (covid, 0.2550966572188687)  \n",
       "Random Forest             (covid, 0.2550966572188687)  \n",
       "XGBoost                   (covid, 0.2550966572188687)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=-1)\n",
      "LogisticRegression(max_iter=1000, n_jobs=-1, penalty='l1', solver='liblinear')\n",
      "LogisticRegression(max_iter=1000, n_jobs=-1)\n",
      "LinearSVC(dual=False, max_iter=10000, penalty='l1')\n",
      "LinearSVC(max_iter=10000)\n",
      "SVC()\n",
      "DecisionTreeClassifier(max_depth=range(1, 15), random_state=0)\n",
      "RandomForestClassifier(max_depth=range(1, 15), random_state=0)\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.01, max_delta_step=None, max_depth=range(1, 15),\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=0, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "knn_c = KNeighborsClassifier(n_jobs=-1)\n",
    "log_res_l1 = LogisticRegression(penalty='l1', max_iter=1000, solver='liblinear', n_jobs=-1)\n",
    "log_res_l2 = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "lin_svc_l1 = LinearSVC(penalty='l1', dual=False, max_iter=10000)\n",
    "lin_svc_l2 = LinearSVC(penalty='l2', max_iter=10000)\n",
    "# cl7 = SVC(kernel='poly', degree=3)\n",
    "depth_settings = range(1, 15)\n",
    "nsvm_rbf = SVC(kernel='rbf')\n",
    "d_tree = DecisionTreeClassifier(random_state=0, max_depth=depth_settings)\n",
    "r_forest = RandomForestClassifier(max_depth=depth_settings, random_state=0)\n",
    "xg_boost = XGBClassifier.XGBClassifier(random_state=0, max_depth=depth_settings, learning_rate=0.01)\n",
    "\n",
    "model_list = [knn_c, log_res_l1, log_res_l2, lin_svc_l1, lin_svc_l2, nsvm_rbf, d_tree, r_forest, xg_boost]\n",
    "model_dict = {}\n",
    "\n",
    "f1_scores_micro = []\n",
    "f1_scores_macro = []\n",
    "f1_scores_weighted = []\n",
    "\n",
    "precision_scores_micro = []\n",
    "precision_scores_macro = []\n",
    "precision_scores_weighted = []\n",
    "\n",
    "recall_scores_micro = []\n",
    "recall_scores_macro = []\n",
    "recall_scores_weighted = []\n",
    "\n",
    "counter = 0\n",
    "model_predict_df = pd.DataFrame()\n",
    "for index, row in model_performances.iterrows():\n",
    "    model_dict[index] = model_list[counter]\n",
    "    curr_model = model_list[counter]\n",
    "    print(curr_model)\n",
    "    curr_model.set_params(**row['Best Parameters'])\n",
    "    trained_curr_model = curr_model.fit(X_train, y_train)\n",
    "    predictions = trained_curr_model.predict(X_val)\n",
    "    \n",
    "    f1_scores_micro.append(f1_score(predictions, y_val, average='micro'))\n",
    "    f1_scores_macro.append(f1_score(predictions, y_val, average='macro'))\n",
    "    f1_scores_weighted.append(f1_score(predictions, y_val, average='weighted'))\n",
    "    \n",
    "    precision_scores_micro.append(precision_score(predictions, y_val, average='micro'))\n",
    "    precision_scores_macro.append(precision_score(predictions, y_val, average='macro'))\n",
    "    precision_scores_weighted.append(precision_score(predictions, y_val, average='weighted'))\n",
    "    \n",
    "    recall_scores_micro.append(recall_score(predictions, y_val, average='micro'))\n",
    "    recall_scores_macro.append(recall_score(predictions, y_val, average='macro'))\n",
    "    recall_scores_weighted.append(recall_score(predictions, y_val, average='weighted'))\n",
    "    \n",
    "    model_predict_df[index] = predictions\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performances['F1 Score Micro'] = f1_scores_micro\n",
    "model_performances['F1 Score Macro'] = f1_scores_macro\n",
    "model_performances['F1 Score Weighted'] = f1_scores_weighted\n",
    "\n",
    "model_performances['Recall Score Micro'] = recall_scores_micro\n",
    "model_performances['Recall Score Macro'] = recall_scores_macro\n",
    "model_performances['Recall Score Weighted'] = recall_scores_weighted\n",
    "\n",
    "model_performances['Precision Score Micro'] = precision_scores_micro\n",
    "model_performances['Precision Score Macro'] = precision_scores_macro\n",
    "model_performances['Precision Score Weighted'] = precision_scores_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Test Accuracy / PCC</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>F1 Score Micro</th>\n",
       "      <th>F1 Score Macro</th>\n",
       "      <th>F1 Score Weighted</th>\n",
       "      <th>Recall Score Micro</th>\n",
       "      <th>Recall Score Macro</th>\n",
       "      <th>Recall Score Weighted</th>\n",
       "      <th>Precision Score Micro</th>\n",
       "      <th>Precision Score Macro</th>\n",
       "      <th>Precision Score Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>8.864727</td>\n",
       "      <td>1.561884</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.426872</td>\n",
       "      <td>0.683909</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.933934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (L1)</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 3.593813663804626}</td>\n",
       "      <td>1.167261</td>\n",
       "      <td>1.703873</td>\n",
       "      <td>[000, 3.0968197254487153]</td>\n",
       "      <td>[10, -3.1131409340708296]</td>\n",
       "      <td>[100, 1.7870790377486958]</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>0.675748</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.682099</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.557505</td>\n",
       "      <td>0.761024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (L2)</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>{'C': 0.021544346900318846}</td>\n",
       "      <td>2.368739</td>\n",
       "      <td>1.632878</td>\n",
       "      <td>[000, 0.09030672183600422]</td>\n",
       "      <td>[10, 0.07339367682126371]</td>\n",
       "      <td>[100, 0.11077148985498345]</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.515058</td>\n",
       "      <td>0.672795</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.776882</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.500975</td>\n",
       "      <td>0.841789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM (L1)</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 0.2782559402207126}</td>\n",
       "      <td>3.026699</td>\n",
       "      <td>1.632878</td>\n",
       "      <td>[000, 0.5895135640250133]</td>\n",
       "      <td>[10, -0.5892319061480008]</td>\n",
       "      <td>[100, 0.3768937967319165]</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.642773</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.664198</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.539961</td>\n",
       "      <td>0.719614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM (L2)</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>{'C': 0.0016681005372000592}</td>\n",
       "      <td>1.145055</td>\n",
       "      <td>1.703873</td>\n",
       "      <td>[000, -0.038204948000019924]</td>\n",
       "      <td>[10, -0.07851418749006081]</td>\n",
       "      <td>[100, -0.06121857876659567]</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.556586</td>\n",
       "      <td>0.692574</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.840209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NonLinear SVM (RBF)</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.979310</td>\n",
       "      <td>{'C': 599.4842503189421, 'gamma': 1e-05}</td>\n",
       "      <td>14.524542</td>\n",
       "      <td>1.703873</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.556586</td>\n",
       "      <td>0.692574</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.840209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.682759</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2.248164</td>\n",
       "      <td>1.632878</td>\n",
       "      <td>(free, 0.127286770052531)</td>\n",
       "      <td>(aeuroesuposta, 0.13115910517599078)</td>\n",
       "      <td>(covid, 0.2550966572188687)</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.537838</td>\n",
       "      <td>0.655252</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.520468</td>\n",
       "      <td>0.758179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>7.993919</td>\n",
       "      <td>1.490889</td>\n",
       "      <td>(free, 0.127286770052531)</td>\n",
       "      <td>(aeuroesuposta, 0.13115910517599078)</td>\n",
       "      <td>(covid, 0.2550966572188687)</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.355780</td>\n",
       "      <td>0.685322</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.957958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>72.688329</td>\n",
       "      <td>1.774868</td>\n",
       "      <td>(free, 0.127286770052531)</td>\n",
       "      <td>(aeuroesuposta, 0.13115910517599078)</td>\n",
       "      <td>(covid, 0.2550966572188687)</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.623647</td>\n",
       "      <td>0.692054</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.741758</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.594542</td>\n",
       "      <td>0.760866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Test Accuracy  Training Accuracy  \\\n",
       "KNN                            0.594595           0.758621   \n",
       "Logistic Regression (L1)       0.648649           1.000000   \n",
       "Logistic Regression (L2)       0.621622           0.972414   \n",
       "Linear SVM (L1)                0.621622           1.000000   \n",
       "Linear SVM (L2)                0.648649           0.965517   \n",
       "NonLinear SVM (RBF)            0.648649           0.979310   \n",
       "Decision Tree                  0.621622           0.682759   \n",
       "Random Forest                  0.567568           0.696552   \n",
       "XGBoost                        0.675676           0.703448   \n",
       "\n",
       "                                                   Best Parameters   Run Time  \\\n",
       "KNN                                            {'n_neighbors': 11}   8.864727   \n",
       "Logistic Regression (L1)                  {'C': 3.593813663804626}   1.167261   \n",
       "Logistic Regression (L2)               {'C': 0.021544346900318846}   2.368739   \n",
       "Linear SVM (L1)                          {'C': 0.2782559402207126}   3.026699   \n",
       "Linear SVM (L2)                       {'C': 0.0016681005372000592}   1.145055   \n",
       "NonLinear SVM (RBF)       {'C': 599.4842503189421, 'gamma': 1e-05}  14.524542   \n",
       "Decision Tree                                     {'max_depth': 5}   2.248164   \n",
       "Random Forest                                    {'max_depth': 10}   7.993919   \n",
       "XGBoost                                           {'max_depth': 3}  72.688329   \n",
       "\n",
       "                          Test Accuracy / PCC                             0  \\\n",
       "KNN                                  1.561884                         [nan]   \n",
       "Logistic Regression (L1)             1.703873     [000, 3.0968197254487153]   \n",
       "Logistic Regression (L2)             1.632878    [000, 0.09030672183600422]   \n",
       "Linear SVM (L1)                      1.632878     [000, 0.5895135640250133]   \n",
       "Linear SVM (L2)                      1.703873  [000, -0.038204948000019924]   \n",
       "NonLinear SVM (RBF)                  1.703873                         [nan]   \n",
       "Decision Tree                        1.632878     (free, 0.127286770052531)   \n",
       "Random Forest                        1.490889     (free, 0.127286770052531)   \n",
       "XGBoost                              1.774868     (free, 0.127286770052531)   \n",
       "\n",
       "                                                             1  \\\n",
       "KNN                                                      [nan]   \n",
       "Logistic Regression (L1)             [10, -3.1131409340708296]   \n",
       "Logistic Regression (L2)             [10, 0.07339367682126371]   \n",
       "Linear SVM (L1)                      [10, -0.5892319061480008]   \n",
       "Linear SVM (L2)                     [10, -0.07851418749006081]   \n",
       "NonLinear SVM (RBF)                                      [nan]   \n",
       "Decision Tree             (aeuroesuposta, 0.13115910517599078)   \n",
       "Random Forest             (aeuroesuposta, 0.13115910517599078)   \n",
       "XGBoost                   (aeuroesuposta, 0.13115910517599078)   \n",
       "\n",
       "                                                    2  F1 Score Micro  \\\n",
       "KNN                                             [nan]        0.594595   \n",
       "Logistic Regression (L1)    [100, 1.7870790377486958]        0.648649   \n",
       "Logistic Regression (L2)   [100, 0.11077148985498345]        0.621622   \n",
       "Linear SVM (L1)             [100, 0.3768937967319165]        0.621622   \n",
       "Linear SVM (L2)           [100, -0.06121857876659567]        0.648649   \n",
       "NonLinear SVM (RBF)                             [nan]        0.648649   \n",
       "Decision Tree             (covid, 0.2550966572188687)        0.621622   \n",
       "Random Forest             (covid, 0.2550966572188687)        0.567568   \n",
       "XGBoost                   (covid, 0.2550966572188687)        0.675676   \n",
       "\n",
       "                          F1 Score Macro  F1 Score Weighted  \\\n",
       "KNN                             0.426872           0.683909   \n",
       "Logistic Regression (L1)        0.578001           0.675748   \n",
       "Logistic Regression (L2)        0.515058           0.672795   \n",
       "Linear SVM (L1)                 0.565217           0.642773   \n",
       "Linear SVM (L2)                 0.556586           0.692574   \n",
       "NonLinear SVM (RBF)             0.556586           0.692574   \n",
       "Decision Tree                   0.537838           0.655252   \n",
       "Random Forest                   0.355780           0.685322   \n",
       "XGBoost                         0.623647           0.692054   \n",
       "\n",
       "                          Recall Score Micro  Recall Score Macro  \\\n",
       "KNN                                 0.594595            0.852941   \n",
       "Logistic Regression (L1)            0.648649            0.682099   \n",
       "Logistic Regression (L2)            0.621622            0.776882   \n",
       "Linear SVM (L1)                     0.621622            0.664198   \n",
       "Linear SVM (L2)                     0.648649            0.800000   \n",
       "NonLinear SVM (RBF)                 0.648649            0.800000   \n",
       "Decision Tree                       0.621622            0.652381   \n",
       "Random Forest                       0.567568            0.514286   \n",
       "XGBoost                             0.675676            0.741758   \n",
       "\n",
       "                          Recall Score Weighted  Precision Score Micro  \\\n",
       "KNN                                    0.594595               0.594595   \n",
       "Logistic Regression (L1)               0.648649               0.648649   \n",
       "Logistic Regression (L2)               0.621622               0.621622   \n",
       "Linear SVM (L1)                        0.621622               0.621622   \n",
       "Linear SVM (L2)                        0.648649               0.648649   \n",
       "NonLinear SVM (RBF)                    0.648649               0.648649   \n",
       "Decision Tree                          0.621622               0.621622   \n",
       "Random Forest                          0.567568               0.567568   \n",
       "XGBoost                                0.675676               0.675676   \n",
       "\n",
       "                          Precision Score Macro  Precision Score Weighted  \n",
       "KNN                                    0.444444                  0.933934  \n",
       "Logistic Regression (L1)               0.557505                  0.761024  \n",
       "Logistic Regression (L2)               0.500975                  0.841789  \n",
       "Linear SVM (L1)                        0.539961                  0.719614  \n",
       "Linear SVM (L2)                        0.538012                  0.840209  \n",
       "NonLinear SVM (RBF)                    0.538012                  0.840209  \n",
       "Decision Tree                          0.520468                  0.758179  \n",
       "Random Forest                          0.407407                  0.957958  \n",
       "XGBoost                                0.594542                  0.760866  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression (L1)</th>\n",
       "      <th>Logistic Regression (L2)</th>\n",
       "      <th>Linear SVM (L1)</th>\n",
       "      <th>Linear SVM (L2)</th>\n",
       "      <th>NonLinear SVM (RBF)</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    KNN  Logistic Regression (L1)  Logistic Regression (L2)  Linear SVM (L1)  \\\n",
       "0    -1                        -1                        -1               -1   \n",
       "1    -1                        -1                        -1               -1   \n",
       "2    -1                        -1                        -1               -1   \n",
       "3    -1                        -1                        -1                1   \n",
       "4    -1                        -1                        -1               -1   \n",
       "5    -1                        -1                        -1               -1   \n",
       "6    -1                         0                        -1               -1   \n",
       "7    -1                        -1                        -1               -1   \n",
       "8    -1                        -1                        -1               -1   \n",
       "9    -1                        -1                        -1               -1   \n",
       "10   -1                        -1                        -1               -1   \n",
       "11   -1                        -1                        -1               -1   \n",
       "12    1                         1                         1                1   \n",
       "13   -1                        -1                        -1               -1   \n",
       "14   -1                        -1                        -1               -1   \n",
       "15    1                         1                         1                1   \n",
       "16   -1                        -1                        -1               -1   \n",
       "17   -1                        -1                        -1               -1   \n",
       "18   -1                         0                         1                0   \n",
       "19   -1                        -1                        -1               -1   \n",
       "20   -1                        -1                        -1               -1   \n",
       "21   -1                         0                        -1                0   \n",
       "22   -1                        -1                        -1               -1   \n",
       "23   -1                        -1                        -1               -1   \n",
       "24   -1                         1                        -1                1   \n",
       "25   -1                        -1                        -1               -1   \n",
       "26   -1                        -1                        -1               -1   \n",
       "27   -1                         0                        -1                0   \n",
       "28   -1                        -1                        -1               -1   \n",
       "29   -1                         0                         0                0   \n",
       "30   -1                        -1                        -1               -1   \n",
       "31   -1                         1                         1                1   \n",
       "32   -1                        -1                        -1               -1   \n",
       "33   -1                        -1                        -1               -1   \n",
       "34   -1                        -1                        -1               -1   \n",
       "35   -1                        -1                        -1               -1   \n",
       "36    0                         0                         0                0   \n",
       "\n",
       "    Linear SVM (L2)  NonLinear SVM (RBF)  Decision Tree  Random Forest  \\\n",
       "0                -1                   -1              0             -1   \n",
       "1                -1                    1             -1             -1   \n",
       "2                -1                   -1             -1             -1   \n",
       "3                -1                   -1              1             -1   \n",
       "4                -1                   -1             -1             -1   \n",
       "5                -1                   -1             -1             -1   \n",
       "6                -1                   -1              0             -1   \n",
       "7                 1                   -1             -1             -1   \n",
       "8                -1                   -1             -1             -1   \n",
       "9                -1                   -1             -1             -1   \n",
       "10               -1                   -1             -1             -1   \n",
       "11               -1                   -1             -1             -1   \n",
       "12                1                    1              1              1   \n",
       "13               -1                   -1             -1             -1   \n",
       "14               -1                   -1             -1             -1   \n",
       "15                1                    1              1              1   \n",
       "16               -1                   -1             -1             -1   \n",
       "17               -1                   -1             -1             -1   \n",
       "18                1                    1             -1             -1   \n",
       "19               -1                   -1             -1             -1   \n",
       "20               -1                   -1             -1             -1   \n",
       "21               -1                   -1              0             -1   \n",
       "22               -1                   -1             -1             -1   \n",
       "23               -1                   -1             -1             -1   \n",
       "24               -1                   -1             -1             -1   \n",
       "25               -1                   -1             -1             -1   \n",
       "26               -1                   -1             -1             -1   \n",
       "27               -1                   -1              0             -1   \n",
       "28               -1                   -1             -1             -1   \n",
       "29                0                    0             -1             -1   \n",
       "30               -1                   -1             -1             -1   \n",
       "31                1                    1              1             -1   \n",
       "32               -1                   -1             -1             -1   \n",
       "33               -1                   -1             -1             -1   \n",
       "34               -1                   -1             -1             -1   \n",
       "35               -1                   -1             -1             -1   \n",
       "36                0                    0              0             -1   \n",
       "\n",
       "    XGBoost  \n",
       "0         0  \n",
       "1         1  \n",
       "2        -1  \n",
       "3        -1  \n",
       "4        -1  \n",
       "5        -1  \n",
       "6         0  \n",
       "7        -1  \n",
       "8        -1  \n",
       "9        -1  \n",
       "10        0  \n",
       "11       -1  \n",
       "12        1  \n",
       "13       -1  \n",
       "14       -1  \n",
       "15        1  \n",
       "16       -1  \n",
       "17       -1  \n",
       "18        0  \n",
       "19       -1  \n",
       "20       -1  \n",
       "21        0  \n",
       "22       -1  \n",
       "23       -1  \n",
       "24       -1  \n",
       "25       -1  \n",
       "26       -1  \n",
       "27        0  \n",
       "28       -1  \n",
       "29       -1  \n",
       "30       -1  \n",
       "31        1  \n",
       "32       -1  \n",
       "33       -1  \n",
       "34       -1  \n",
       "35       -1  \n",
       "36        0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict_df.to_csv('all_model_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithms</th>\n",
       "      <th>Algorithms</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>percent of PCC</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>F1 Score Macro</th>\n",
       "      <th>F1 Score Weighted</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score Micro</th>\n",
       "      <th>Recall Score Macro</th>\n",
       "      <th>Recall Score Weighted</th>\n",
       "      <th>Precision Score Micro</th>\n",
       "      <th>Precision Score Macro</th>\n",
       "      <th>Precision Score Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>1.309995</td>\n",
       "      <td>1.347617</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression (L1)</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 599.4842503189421}</td>\n",
       "      <td>3.868001</td>\n",
       "      <td>1.631326</td>\n",
       "      <td>['000', -1.2262577545315585]</td>\n",
       "      <td>['0a08dwsjty', -2.8805869509602426]</td>\n",
       "      <td>['0wzxb3n4j9', -2.7253698076951407]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569573</td>\n",
       "      <td>0.686256</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.756152</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.540789</td>\n",
       "      <td>0.830974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Logistic Regression (L2)</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 0.2782559402207126}</td>\n",
       "      <td>2.160705</td>\n",
       "      <td>1.702253</td>\n",
       "      <td>['000', -0.16885605165841644]</td>\n",
       "      <td>['0a08dwsjty', 0.2817473148696053]</td>\n",
       "      <td>['0wzxb3n4j9', 0.24544967884729332]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>0.688224</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.815505</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.540789</td>\n",
       "      <td>0.815505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Linear SVM (L1)</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 0.2782559402207126}</td>\n",
       "      <td>1.866419</td>\n",
       "      <td>1.702253</td>\n",
       "      <td>['000', 0.46233130606259887]</td>\n",
       "      <td>['0a08dwsjty', 0.350727918862724]</td>\n",
       "      <td>['0wzxb3n4j9', 0.37312739526826555]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555319</td>\n",
       "      <td>0.687752</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.540789</td>\n",
       "      <td>0.798009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Linear SVM (L2)</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'C': 0.0016681005372000592}</td>\n",
       "      <td>0.543514</td>\n",
       "      <td>1.702253</td>\n",
       "      <td>['000', -0.04141675364049047]</td>\n",
       "      <td>['0a08dwsjty', -0.06455537526105888]</td>\n",
       "      <td>['0wzxb3n4j9', -0.05927501040747649]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552536</td>\n",
       "      <td>0.685958</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.780512</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.540789</td>\n",
       "      <td>0.780512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithms                Algorithms  Test Accuracy  Training Accuracy  \\\n",
       "0          0                       KNN       0.513514           0.586207   \n",
       "1          1  Logistic Regression (L1)       0.621622           1.000000   \n",
       "2          2  Logistic Regression (L2)       0.648649           1.000000   \n",
       "3          3           Linear SVM (L1)       0.648649           1.000000   \n",
       "4          4           Linear SVM (L2)       0.648649           1.000000   \n",
       "\n",
       "                Best Parameters  Run Time  percent of PCC  \\\n",
       "0           {'n_neighbors': 11}  1.309995        1.347617   \n",
       "1      {'C': 599.4842503189421}  3.868001        1.631326   \n",
       "2     {'C': 0.2782559402207126}  2.160705        1.702253   \n",
       "3     {'C': 0.2782559402207126}  1.866419        1.702253   \n",
       "4  {'C': 0.0016681005372000592}  0.543514        1.702253   \n",
       "\n",
       "                               0                                     1  \\\n",
       "0                          [nan]                                 [nan]   \n",
       "1   ['000', -1.2262577545315585]   ['0a08dwsjty', -2.8805869509602426]   \n",
       "2  ['000', -0.16885605165841644]    ['0a08dwsjty', 0.2817473148696053]   \n",
       "3   ['000', 0.46233130606259887]     ['0a08dwsjty', 0.350727918862724]   \n",
       "4  ['000', -0.04141675364049047]  ['0a08dwsjty', -0.06455537526105888]   \n",
       "\n",
       "                                      2  ...  F1 Score Macro  \\\n",
       "0                                 [nan]  ...        0.226190   \n",
       "1   ['0wzxb3n4j9', -2.7253698076951407]  ...        0.569573   \n",
       "2   ['0wzxb3n4j9', 0.24544967884729332]  ...        0.559524   \n",
       "3   ['0wzxb3n4j9', 0.37312739526826555]  ...        0.555319   \n",
       "4  ['0wzxb3n4j9', -0.05927501040747649]  ...        0.552536   \n",
       "\n",
       "   F1 Score Weighted  Recall Score  Precision Score  Recall Score Micro  \\\n",
       "0           0.678571      0.513514         1.000000            0.513514   \n",
       "1           0.686256      0.621622         0.756152            0.648649   \n",
       "2           0.688224      0.648649         0.815505            0.648649   \n",
       "3           0.687752      0.648649         0.798009            0.648649   \n",
       "4           0.685958      0.648649         0.780512            0.648649   \n",
       "\n",
       "   Recall Score Macro  Recall Score Weighted  Precision Score Micro  \\\n",
       "0            0.171171               0.513514               0.513514   \n",
       "1            0.783333               0.648649               0.648649   \n",
       "2            0.706897               0.648649               0.648649   \n",
       "3            0.664286               0.648649               0.648649   \n",
       "4            0.638889               0.648649               0.648649   \n",
       "\n",
       "   Precision Score Macro  Precision Score Weighted  \n",
       "0               0.333333                  1.000000  \n",
       "1               0.540789                  0.830974  \n",
       "2               0.540789                  0.815505  \n",
       "3               0.540789                  0.798009  \n",
       "4               0.540789                  0.780512  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performances = pd.read_csv('model_performances.csv')\n",
    "model_performances_copy = model_performances.copy()\n",
    "model_performances_copy.rename(columns={'Unnamed: 0': 'Algorithms'}, inplace=True)\n",
    "model_performances_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performances_copy.to_csv('model_performances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Numbers = [3,6,27]\n",
    "\n",
    "my_labels = 'Positive','Neutral','Negative'\n",
    "colors = [\"royalblue\", \"bisque\", \"firebrick\"]\n",
    "plt.pie(Numbers,labels=my_labels,autopct='%1.1f%%', colors=colors)\n",
    "plt.title('XGBoost')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "data = {'Models': ['KNN', 'Logistic Regression (L1)', 'Logistic Regression (L2)', 'Linear SVM (L1)', 'Linear SVM (L2)',\n",
    "        'Non Linear SVM (RBF)', 'Decision Tree', 'Random Forest', 'XGBoost'], \n",
    "        'F1 Micro Scores': [0.540541, 0.621622, 0.621622, 0.648649, 0.648649, 0.621622, 0.540541, 0.540541, 0.675676]}\n",
    "df = pd.DataFrame(data)  \n",
    "\n",
    "#sns.barplot(x='Models', y='F1 Micro Scores', data=df, order=df.sort_values('F1 Micro Scores', ascending=False).Models)\n",
    "\n",
    "#labels = np.array(df.Name)\n",
    "#values = np.array(df.Score) \n",
    "clrs = ['grey' if (x < max(df['F1 Micro Scores'])) else 'brown' for x in df['F1 Micro Scores'] ]\n",
    "#Configure the size\n",
    "plt.figure(figsize=(20,8))\n",
    "#barplot\n",
    "sns.barplot(x=df['Models'], y=df['F1 Micro Scores'], data=df, order=df.sort_values('F1 Micro Scores', ascending=True).Models, palette=clrs) # color=clrs)\n",
    "#Rotate x-labels \n",
    "plt.xticks(rotation=40)\n",
    "#plt.title('F1 Micro Scores of Models')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
